{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORqAaJS3LEuO"
      },
      "source": [
        "# Information Retrieval and Web Analytics\n",
        "\n",
        "# PROJECT PART 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoFeNxSnPQjl"
      },
      "source": [
        "Group Members:\n",
        "\n",
        "*   Berta Alòs (228709)\n",
        "*   Maria Cerezo (183213)\n",
        "*   Paula Vilà (231630)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b6Kvwt0KHFe"
      },
      "source": [
        "Load packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdAN9x9fLRSQ",
        "outputId": "0a867a76-b48b-4c89-c1a2-6a3fc4e9ea84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "from array import array\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import math\n",
        "import numpy as np\n",
        "import collections\n",
        "import json \n",
        "from numpy import linalg as la\n",
        "import pandas as pd \n",
        "import re\n",
        "from operator import itemgetter\n",
        "import unicodedata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjHAZxQfLASO"
      },
      "source": [
        "# Data preparation and Text processing\n",
        "The dataset is stored in the JSON file. It contains 4000 Hurricane Ian tweets. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reading json file and transforming it into pandas dataframe\n",
        "tw_data = pd.read_json('tw_hurricane_data.json',lines=True)\n",
        "\n",
        "#reading the csv file and transforming it into pandas dataframe\n",
        "map_data = pd.read_csv('tweet_document_ids_map.csv',\n",
        "                    sep='::', \n",
        "                    encoding='latin-1',\n",
        "                    engine='python',\n",
        "                    names=['documents IDs'])"
      ],
      "metadata": {
        "id": "Z-jYHN1tXNLW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a new dataframe with the desired columns extracted from tw_data dataframe \n",
        "tw_fields = pd.DataFrame()\n",
        "tw_fields['hashtags']=None\n",
        "tw_fields['name']=None\n",
        "tw_fields['full_text']=None\n",
        "tw_fields['created_at']=None\n",
        "tw_fields['favorite_count']=None\n",
        "tw_fields['retweet_count']=None\n",
        "tw_fields['url']=None\n",
        "\n",
        "#creating a column with hashtag information obtained from entities column\n",
        "tw_fields['hashtags'] = tw_data['entities'].apply(lambda x: x.get('hashtags'))\n",
        "\n",
        "#creating a column with username information obtained from user column\n",
        "tw_fields['name'] = tw_data['user'].apply(lambda x: x.get('name'))\n",
        "\n",
        "#creating a column with url information obtained from entities column\n",
        "for i in tw_data.index:\n",
        "  tw_fields['url'][i]=tw_data['entities'][i]['media'][0]['url'] if(tw_data['entities'][i].get('media') is not None) else {}\n",
        "\n",
        "#creating a column with the full_text information of the tw_data dataframe\n",
        "tw_fields['full_text']=tw_data['full_text']\n",
        "\n",
        "#creating a column with the created_at information of the tw_data dataframe\n",
        "tw_fields['created_at']=tw_data['created_at']\n",
        "\n",
        "#creating a column with the favorite_count information of the tw_data dataframe\n",
        "tw_fields['favorite_count']=tw_data['favorite_count']\n",
        "\n",
        "#creating a column with the retweet_count information of the tw_data dataframe\n",
        "tw_fields['retweet_count']=tw_data['retweet_count']"
      ],
      "metadata": {
        "id": "Rrr4-mWF6m0F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a new dataset containing the required columns, with it's specified column names\n",
        "tw_fields = pd.DataFrame({'Tweet' : tw_fields['full_text'],'Username' : tw_fields['name'],  'Date' : tw_fields['created_at'],'Hashtags' : tw_fields['hashtags'], 'Likes' : tw_fields['favorite_count'], 'Retweets' : tw_fields['retweet_count'], 'Url' : tw_fields['url']})"
      ],
      "metadata": {
        "id": "kQ9OsPqsdenA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JGMyctHv1H9c"
      },
      "outputs": [],
      "source": [
        "#Function to preprocess data\n",
        "def build_terms(line):\n",
        "    \"\"\"\n",
        "    Preprocess the text removing stop words, stemming, transforming in \n",
        "    lowercase, removing URLs and emojis, removing everything it is not a digit \n",
        "    nor number and return the tokens of the text.\n",
        "    \n",
        "    Argument:\n",
        "    line -- string (text) to be preprocessed\n",
        "    \n",
        "    Returns:\n",
        "    line - a list of tokens corresponding to the input text after the preprocessing\n",
        "    \"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    line = str(unicodedata.normalize('NFKD', line).encode('ASCII', 'ignore')) [2:-1] #BONUS: Romanizing the text\n",
        "    line=re.sub(r'[\\W_]+', ' ', line) #BONUS: Removing anything is not a letter or digit\n",
        "    line = line.lower() \n",
        "    line = line.split()  # Tokenize the text to get a list of terms\n",
        "    line = [x for x in line if x not in stop_words]  # eliminate the stopwords\n",
        "    line = [stemmer.stem(word) for word in line] # perform stemming (HINT: use List Comprehension)\n",
        "    line = [l for l in line if \"https://\" not in l ] #BONUS: Removing the URLs from the line\n",
        "    line = [emojis_out(l) for l in line ] ##BONUS: removing the emojis from the line\n",
        "    return line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dQwkYdhBQxYa"
      },
      "outputs": [],
      "source": [
        "#Function to get rid of emojis\n",
        "def emojis_out (s):\n",
        "    \"\"\"Preprocess the text removing stop emojis from of the string\n",
        "    \n",
        "    Arguments:\n",
        "    s -- string (word) to be processed\n",
        "    \n",
        "    Returns: \n",
        "    word-- string equal to \"\" if it's  an emoji and \"s\" otherwise. \n",
        "    \"\"\"\n",
        "    emoji_pattern = re.compile(\"[\"  \n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # removing symbols & pictographs  \n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "       \n",
        "    word = emoji_pattern.sub(r'', s)\n",
        "    return word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puDHJr85FGWr"
      },
      "outputs": [],
      "source": [
        "#preprocessing the Tweet and Username information\n",
        "for i in tw_fields.index: \n",
        "    tw_fields['Tweet'][i] = build_terms(tw_fields['Tweet'][i]) \n",
        "    tw_fields['Username'][i]=emojis_out(tw_fields['Username'][i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merging the tw_fields & map_data dataframes into a single dataframe named final_dataset\n",
        "final_dataset=pd.merge(map_data, tw_fields, left_index=True, right_index=True)  \n",
        "final_dataset.head(3) #displaying the first 3 rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "RjdSEYfrArpr",
        "outputId": "44a7aa75-0501-489f-9312-69a50a170793"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                documents IDs  \\\n",
              "0  doc_1\\t1575918182698979328   \n",
              "1  doc_2\\t1575918151862304768   \n",
              "2  doc_3\\t1575918140839673873   \n",
              "\n",
              "                                               Tweet           Username  \\\n",
              "0  [keep, spin, us, 7, pm, go, away, alreadi, hur...                Suz   \n",
              "1  [heart, go, affect, hurricaneian, wish, everyo...               Lytx   \n",
              "2  [kissimme, neighborhood, michigan, ave, n, hur...  Christopher Heath   \n",
              "\n",
              "                       Date                                         Hashtags  \\\n",
              "0 2022-09-30 18:39:08+00:00  [{'text': 'HurricaneIan', 'indices': [63, 76]}]   \n",
              "1 2022-09-30 18:39:01+00:00  [{'text': 'HurricaneIan', 'indices': [43, 56]}]   \n",
              "2 2022-09-30 18:38:58+00:00  [{'text': 'HurricaneIan', 'indices': [45, 58]}]   \n",
              "\n",
              "   Likes  Retweets                      Url  \n",
              "0      0         0  https://t.co/VROTxNS9rz  \n",
              "1      0         0                       {}  \n",
              "2      0         0  https://t.co/jf7zseg0Fe  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-892c494e-ed17-412c-a205-a0d0304fd82f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>documents IDs</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Username</th>\n",
              "      <th>Date</th>\n",
              "      <th>Hashtags</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>doc_1\\t1575918182698979328</td>\n",
              "      <td>[keep, spin, us, 7, pm, go, away, alreadi, hur...</td>\n",
              "      <td>Suz</td>\n",
              "      <td>2022-09-30 18:39:08+00:00</td>\n",
              "      <td>[{'text': 'HurricaneIan', 'indices': [63, 76]}]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>https://t.co/VROTxNS9rz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>doc_2\\t1575918151862304768</td>\n",
              "      <td>[heart, go, affect, hurricaneian, wish, everyo...</td>\n",
              "      <td>Lytx</td>\n",
              "      <td>2022-09-30 18:39:01+00:00</td>\n",
              "      <td>[{'text': 'HurricaneIan', 'indices': [43, 56]}]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>doc_3\\t1575918140839673873</td>\n",
              "      <td>[kissimme, neighborhood, michigan, ave, n, hur...</td>\n",
              "      <td>Christopher Heath</td>\n",
              "      <td>2022-09-30 18:38:58+00:00</td>\n",
              "      <td>[{'text': 'HurricaneIan', 'indices': [45, 58]}]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>https://t.co/jf7zseg0Fe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-892c494e-ed17-412c-a205-a0d0304fd82f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-892c494e-ed17-412c-a205-a0d0304fd82f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-892c494e-ed17-412c-a205-a0d0304fd82f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}